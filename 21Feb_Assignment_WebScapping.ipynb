{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c7411d-9140-4766-a91b-d64050c8d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "542c8882-c8e5-4fe4-8074-f4997452ba63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMost Common Uses of Web Scraping:\\n1. Data Analysis\\n2. E-Commerce\\n3. Training and Testing Data for Machine Learning Projects '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Web scraping is the process of using bots to extract content and data from a website. Unlike screen scraping, which only copies pixels displayed onscreen, web scraping extracts underlying HTML code and, with it, data stored in a database. The scraper can then replicate entire website content elsewhere.\n",
    "\"\"\"\n",
    "Most Common Uses of Web Scraping:\n",
    "1. Data Analysis\n",
    "2. E-Commerce\n",
    "3. Training and Testing Data for Machine Learning Projects \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cacd195-b4dc-4249-8b2f-1205b6bcbc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21720515-697a-4430-b145-8c8d2c2aeabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    \\n1. HTML Parsing\\n2. DOM Parsing\\n3. Vertical Aggregation\\n4. XPath '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different methods used for Web Scraping:\n",
    "\"\"\"    \n",
    "1. HTML Parsing\n",
    "2. DOM Parsing\n",
    "3. Vertical Aggregation\n",
    "4. XPath \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1745c57-7978-411f-ba90-f8918c660b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b97bae0-b99e-4b66-999d-72cfe4b5f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beautiful Soup is a Python package for parsing HTML and XML documents (including having malformed markup, i.e. non-closed tags, so named after tag soup). \n",
    "#It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6d7d93-2cfe-4ea8-bfad-8ed0694b8586",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f6c51f-77b0-4177-a77e-71f92ba315c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flask is a lightweight framework to build websites. We'll use this to parse our collected data and display it as HTML in a new HTML file. The requests module allows us to send http requests to the website we want to scrape. \n",
    "#The first line imports the Flask class and the render_template method from the flask library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d56017a-52f1-473b-82c6-721b2b92f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a35a98e-68f0-41df-a0e7-79c6c62b876e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amazon S3, at its core, facilitates object storage, providing leading scalability, data availability, security, and performance. Businesses of vast sizes can leverage S3 for storage and protect large sums of data for various use cases, such as websites, applications, backup, and more.\\n\\nAmazon S3’s intuitive management features enable the frictionless organization of data and configurable access controls.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Amazon EC2 (Elastic Compute Cloud):\n",
    "\"\"\"EC2 is a cloud platform provided by Amazon that offers secure, and resizable compute capacity. Its purpose is to enable easy access and usability to developers for web-scale cloud computing, while allowing for total control of your compute resources.\n",
    "\n",
    "Deploy applications rapidly without the need for investing in hardware upfront; all the while able to launch virtual servers as-needed and at scale.\"\"\"\n",
    "\n",
    "#2. Amazon RDS (Relational Database Services):\n",
    "\"\"\"Amazon Relational Database Service (Amazon RDS) makes database configuration, management, and scaling easy in the cloud. Automate tedious tasks such as hardware provisioning, database arrangement, patching, and backups – cost-effectively and proportionate to your needs.\n",
    "\n",
    "RDS is available on various database instances which are optimized for performance and memory, providing six familiar database engines including Amazon Aurora, PostgreSQL, MySQL, MariaDB, Oracle. database, and SQL server. By leveraging the AWS Database Migration Service, you can easily migrate or reproduce your existing databases to Amazon RDS. Visit Amazon’s RDS page.\"\"\"\n",
    "#3. Amazon S3 (Simple Storage Service):\n",
    "\"\"\"Amazon S3, at its core, facilitates object storage, providing leading scalability, data availability, security, and performance. Businesses of vast sizes can leverage S3 for storage and protect large sums of data for various use cases, such as websites, applications, backup, and more.\n",
    "\n",
    "Amazon S3’s intuitive management features enable the frictionless organization of data and configurable access controls.\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
